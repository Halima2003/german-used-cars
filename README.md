# üöó Analyse de Donn√©es Automobiles

Projet d'analyse de donn√©es de voitures avec Machine Learning pour pr√©dire les prix et identifier les segments de march√©.

---

## üìå Description du projet

Ce projet analyse un dataset de voitures allemandes pour :
- Pr√©dire les prix des v√©hicules
- Identifier diff√©rents segments de march√©
- D√©tecter les marques surcot√©es ou sous-cot√©es

---

## üî¨ M√©thodologie

### 1. **Pr√©paration des donn√©es**
- Normalisation des noms de colonnes
- D√©tection automatique des colonnes (prix, marque, kilom√©trage, puissance, ann√©e)
- Conversion des types de donn√©es
- Calcul de l'√¢ge des v√©hicules (ann√©e actuelle - ann√©e du v√©hicule)
- Filtrage des valeurs aberrantes
- Gestion des valeurs manquantes

### 2. **Analyse exploratoire**
- Distribution des prix et √¢ges
- Corr√©lation entre prix et √¢ge
- Analyse par tranche d'√¢ge
- Identification des marques les plus pr√©sentes

### 3. **Machine Learning**
- **Features utilis√©es** : √¢ge, puissance, kilom√©trage, marque, type de carburant, transmission
- **Encodage** des variables cat√©gorielles
- **3 mod√®les compar√©s** :
  - LightGBM
  - XGBoost
  - RandomForest
- **M√©triques** : MAE, RMSE, R¬≤
- S√©lection du meilleur mod√®le
- Analyse de l'importance des variables

### 4. **Clustering**
- **Algorithme** : K-Means (5 clusters)
- **Normalisation** des donn√©es avec StandardScaler
- **Visualisation** en 2D avec PCA
- Profils moyens par cluster
- Labels descriptifs pour chaque segment

### 5. **Analyse de surcote**
- Calcul des r√©sidus (√©cart entre prix r√©el et pr√©dit)
- Identification des marques surcot√©es
- Visualisation par marque

---

## üõ†Ô∏è Technologies

- **Python 3.8+**
- **Pandas** - Manipulation de donn√©es
- **NumPy** - Calculs num√©riques
- **Scikit-learn** - Machine Learning (preprocessing, clustering, m√©triques)
- **LightGBM & XGBoost** - Mod√®les de pr√©diction
- **Matplotlib & Seaborn** - Visualisations
- **Jupyter Notebook** - Environnement de d√©veloppement

---

## üìñ Utilisation

```python
# 1. Charger les donn√©es
df = pd.read_excel(r'chemin/vers/votre_fichier.xlsx')

# 2. Nettoyer les donn√©es
df_clean = clean_data(df)

# 3. Analyse exploratoire
exploratory_analysis(df_clean)

# 4. Machine Learning
X, y, features, data_ml = prepare_ml_features(df_clean)
best_model, X_test, y_test, y_pred = train_and_compare_models(X, y)

# 5. Clustering
df_final = perform_clustering(df_clean)
```

---
## üë§ Auteur

**Halima**  
Projet d'analyse de donn√©es - 2024
